#!/usr/bin/env python3
"""
æœ€çµ‚ã‚¹ãƒãƒ¼ãƒˆæ¥½è­œæŠ½å‡º V14 - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç‰ˆ
V9ã®å®Ÿè¨¼æ¸ˆã¿OCRãƒ­ã‚¸ãƒƒã‚¯ + V13ã®ç©ºé–“èªè­˜ãƒãƒƒãƒ”ãƒ³ã‚°

æ ¹æœ¬å•é¡Œè§£æ±ºã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼š
1. V9ã®OCRãƒ­ã‚¸ãƒƒã‚¯ï¼ˆæ¥½å™¨æ¤œå‡ºã¯æˆåŠŸã—ã¦ã„ã‚‹ï¼‰
2. V13ã®2æ¬¡å…ƒç©ºé–“ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆä½ç½®å¯¾å¿œã‚’æ”¹å–„ï¼‰
3. ã“ã®çµ„ã¿åˆã‚ã›ã§ã€Œæ¥½å™¨åã¯èª­ã‚ã‚‹ãŒä½ç½®ãŒé–“é•ã†ã€å•é¡Œã‚’è§£æ±º
"""

import fitz
import cv2
import numpy as np
import pytesseract
import os
import re
from datetime import datetime
from typing import List, Tuple, Dict, Optional

class FinalSmartExtractorV14Hybrid:
    def __init__(self):
        self.target_instruments = ['Vocal', 'Vo', 'V', 'Key', 'Keyboard', 'Kb', 'Piano', 'Pf']
        self.exclude_instruments = ['Guitar', 'Gt', 'Bass', 'Ba', 'Drum', 'Dr', 'Percussion', 'Perc']
        
        # V14: V9 + V13ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è¨­å®š
        self.debug_mode = True
        
    def extract_smart_final(self, pdf_path: str) -> Optional[str]:
        """V14ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æŠ½å‡ºï¼šV9 OCR + V13ç©ºé–“ãƒãƒƒãƒ”ãƒ³ã‚°"""
        print("\\nğŸ§© Final Smart Extraction V14 Hybrid")
        print("  - Input:", os.path.basename(pdf_path))
        print("  - Strategy: V9 OCR + V13 Spatial Mapping")
        print("  - Target: Fix instrument-to-staff mapping issue")
        
        try:
            pdf = fitz.open(pdf_path)
            
            # V9ã‚¹ã‚¿ã‚¤ãƒ«ã§ã‚¹ã‚³ã‚¢æ¤œå‡º
            score_start_page = self.detect_score_start_v9(pdf)
            print(f"Score detected starting at page {score_start_page + 1}")
            
            # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æŠ½å‡ºå®Ÿè¡Œ
            all_systems = []
            
            for page_num in range(score_start_page, min(score_start_page + 5, len(pdf))):  # 5ãƒšãƒ¼ã‚¸åˆ¶é™
                print(f"\\n  ğŸ“„ Hybrid Analysis: Page {page_num + 1}")
                
                systems = self.hybrid_system_extraction(pdf[page_num], page_num)
                all_systems.extend(systems)
                
                if self.debug_mode:
                    print(f"    ğŸ“Š Extracted {len(systems)} systems from page {page_num + 1}")
            
            if not all_systems:
                print("âŒ No systems extracted with hybrid approach")
                return None
            
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ¥½å™¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            target_systems = self.filter_target_instruments(all_systems)
            
            # PDFå‡ºåŠ›
            output_path = self.create_hybrid_output(target_systems, pdf_path, pdf)
            
            pdf.close()
            return output_path
            
        except Exception as e:
            print(f"âŒ V14 Hybrid extraction error: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def detect_score_start_v9(self, pdf: fitz.Document) -> int:
        """V9ã‚¹ã‚¿ã‚¤ãƒ«ã®ã‚¹ã‚³ã‚¢é–‹å§‹æ¤œå‡ºï¼ˆå®Ÿè¨¼æ¸ˆã¿ï¼‰"""
        for page_num in range(len(pdf)):
            page = pdf[page_num]
            
            # äº”ç·šè­œã®å­˜åœ¨ã‚’æ¤œå‡ºï¼ˆV9ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
            mat = fitz.Matrix(2.0, 2.0)
            pix = page.get_pixmap(matrix=mat)
            img = np.frombuffer(pix.pil_tobytes(format="PNG"), np.uint8)
            img = cv2.imdecode(img, cv2.IMREAD_COLOR)
            
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            lines = cv2.HoughLines(gray, 1, np.pi/180, threshold=100)
            
            if lines is not None and len(lines) > 10:
                return max(0, page_num)
        
        return max(0, min(1, len(pdf) - 1))
    
    def hybrid_system_extraction(self, page: fitz.Page, page_num: int) -> List[Dict]:
        """V14ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼šV9 OCR + V13ç©ºé–“ãƒãƒƒãƒ”ãƒ³ã‚°"""
        
        # Step 1: V9ã‚¹ã‚¿ã‚¤ãƒ«ã§ã‚¹ã‚¿ãƒƒãƒ•æ¤œå‡º
        staff_groups = self.detect_staff_groups_v9(page)
        
        if self.debug_mode:
            print(f"    ğŸ¼ V9 Staff Detection: {len(staff_groups)} staff groups")
        
        systems = []
        
        # Step 2: å„ã‚¹ã‚¿ãƒƒãƒ•ã‚°ãƒ«ãƒ¼ãƒ—ã§æ¥½å™¨æ¤œå‡ºï¼ˆV9ãƒ­ã‚¸ãƒƒã‚¯ï¼‰+ ç©ºé–“ãƒãƒƒãƒ”ãƒ³ã‚°æ”¹å–„
        for system_idx, staff_group in enumerate(staff_groups):
            if system_idx >= 10:  # åˆ¶é™
                break
                
            if self.debug_mode and system_idx < 5:
                print(f"      System {system_idx + 1}: Analyzing {len(staff_group)} staves")
            
            # V9ã‚¹ã‚¿ã‚¤ãƒ«ã®æ¥½å™¨æ¤œå‡ºï¼ˆOCRï¼‰
            instruments_v9 = self.detect_instruments_v9_ocr(page, staff_group, system_idx)
            
            # V13ã‚¹ã‚¿ã‚¤ãƒ«ã®ç©ºé–“æ¤œè¨¼
            spatial_validation = self.validate_spatial_relationship_v13(page, staff_group, instruments_v9)
            
            if instruments_v9['vocal'] >= 0.5 or instruments_v9['keyboard'] >= 0.5:
                # ã‚·ã‚¹ãƒ†ãƒ çŸ©å½¢è¨ˆç®—
                system_rect = self.calculate_system_rect_v9(staff_group, page)
                
                if system_rect:
                    systems.append({
                        'page_num': page_num,
                        'system_idx': system_idx,
                        'rect': system_rect,
                        'instruments_v9': instruments_v9,
                        'spatial_valid': spatial_validation,
                        'staff_count': len(staff_group)
                    })
                    
                    if self.debug_mode and system_idx < 5:
                        detected = []
                        if instruments_v9['vocal'] >= 0.5: 
                            detected.append(f"Vocal({instruments_v9['vocal']:.1f})")
                        if instruments_v9['keyboard'] >= 0.5: 
                            detected.append(f"Keyboard({instruments_v9['keyboard']:.1f})")
                        
                        spatial_status = "âœ…" if spatial_validation else "âš ï¸"
                        print(f"        {spatial_status} {', '.join(detected) if detected else 'None'}")
        
        return systems
    
    def detect_staff_groups_v9(self, page: fitz.Page) -> List[List[Tuple]]:
        """V9ã®å®Ÿè¨¼æ¸ˆã¿ã‚¹ã‚¿ãƒƒãƒ•æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯"""
        mat = fitz.Matrix(2.5, 2.5)
        pix = page.get_pixmap(matrix=mat)
        img = np.frombuffer(pix.pil_tobytes(format="PNG"), np.uint8)
        img = cv2.imdecode(img, cv2.IMREAD_COLOR)
        
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # V9ã¨åŒã˜æ°´å¹³ç·šæ¤œå‡º
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        morph = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)
        lines = cv2.HoughLines(morph, 1, np.pi/180, threshold=150)
        
        if lines is None:
            return []
        
        # Yåº§æ¨™æŠ½å‡ºã¨ã‚½ãƒ¼ãƒˆ
        h_lines = []
        for line in lines:
            rho, theta = line[0]
            if abs(theta) < 0.1 or abs(theta - np.pi) < 0.1:
                y = rho / np.sin(theta) if abs(np.sin(theta)) > 0.1 else rho
                h_lines.append(int(y / 2.5))
        
        h_lines = sorted(list(set(h_lines)))  # é‡è¤‡é™¤å»ã¨ã‚½ãƒ¼ãƒˆ
        
        # äº”ç·šè­œã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆV9ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
        staff_groups = []
        i = 0
        while i < len(h_lines) - 4:
            group = []
            for j in range(5):
                if i + j < len(h_lines):
                    y = h_lines[i + j]
                    group.append((0, y, page.rect.width, y + 10))
            
            if len(group) == 5:
                gaps = [group[k+1][1] - group[k][3] for k in range(4)]
                avg_gap = sum(gaps) / len(gaps) if gaps else 0
                
                if avg_gap < 15:
                    staff_groups.append(group)
                    i += 5
                else:
                    i += 1
            else:
                i += 1
        
        return staff_groups
    
    def detect_instruments_v9_ocr(self, page: fitz.Page, staff_group: List[Tuple], system_idx: int) -> Dict[str, float]:
        """V9ã®å®Ÿè¨¼æ¸ˆã¿OCRã«ã‚ˆã‚‹æ¥½å™¨æ¤œå‡º"""
        if not staff_group:
            return {'vocal': 0.0, 'keyboard': 0.0}
        
        # V9ã¨åŒã˜é ˜åŸŸè¨­å®š
        top_y = min(staff[1] for staff in staff_group) - 30
        bottom_y = max(staff[1] for staff in staff_group) + 30
        
        # å·¦ç«¯ã®ãƒ©ãƒ™ãƒ«é ˜åŸŸï¼ˆV9è¨­å®šï¼‰
        label_rect = fitz.Rect(0, top_y, 150, bottom_y)
        
        try:
            # OCRã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆV9ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
            text_dict = page.get_textbox(label_rect)
            text = text_dict if isinstance(text_dict, str) else ""
            
            vocal_confidence = 0.0
            keyboard_confidence = 0.0
            
            # V9ã¨åŒã˜ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
            vocal_patterns = ['Vocal', 'Vo', 'V.', 'ãƒœãƒ¼ã‚«ãƒ«', 'æ­Œ', 'Vox']
            keyboard_patterns = ['Key', 'Keyboard', 'Kb', 'Piano', 'Pf', 'ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰', 'ãƒ”ã‚¢ãƒ']
            
            for pattern in vocal_patterns:
                if pattern.lower() in text.lower():
                    vocal_confidence = max(vocal_confidence, 0.9)
            
            for pattern in keyboard_patterns:
                if pattern.lower() in text.lower():
                    keyboard_confidence = max(keyboard_confidence, 0.9)
            
            # V9ã®è£œåŠ©çš„åˆ¤å®šã‚‚å«ã‚ã‚‹
            if vocal_confidence < 0.5:
                note_density = self.estimate_note_density(page, staff_group)
                if note_density > 0.3:
                    vocal_confidence = max(vocal_confidence, 0.6)
            
            if keyboard_confidence < 0.5:
                chord_density = self.estimate_chord_density(page, staff_group)
                if chord_density > 0.2:
                    keyboard_confidence = max(keyboard_confidence, 0.6)
            
            if self.debug_mode and system_idx < 3:
                if vocal_confidence > 0.5 or keyboard_confidence > 0.5:
                    print(f"          OCR text: '{text[:30]}...'")
                    print(f"          Vocal: {vocal_confidence:.1f}, Keyboard: {keyboard_confidence:.1f}")
            
            return {
                'vocal': vocal_confidence,
                'keyboard': keyboard_confidence
            }
            
        except Exception as e:
            if self.debug_mode and system_idx < 3:
                print(f"          OCR error: {e}")
            return {'vocal': 0.0, 'keyboard': 0.0}
    
    def validate_spatial_relationship_v13(self, page: fitz.Page, staff_group: List[Tuple], instruments: Dict[str, float]) -> bool:
        """V13ç©ºé–“é–¢ä¿‚æ¤œè¨¼"""
        # åŸºæœ¬çš„ãªç©ºé–“å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        if not staff_group:
            return False
        
        # ã‚¹ã‚¿ãƒƒãƒ•ã®å‚ç›´ä½ç½®
        staff_center_y = sum(staff[1] for staff in staff_group) / len(staff_group)
        
        # ãƒšãƒ¼ã‚¸å†…ã§ã®ç›¸å¯¾ä½ç½®ãƒã‚§ãƒƒã‚¯
        relative_position = staff_center_y / page.rect.height
        
        # æ¥½å™¨ç¨®åˆ¥ã¨ä½ç½®ã®å¦¥å½“æ€§
        if instruments['vocal'] >= 0.5:
            # ãƒœãƒ¼ã‚«ãƒ«ã¯é€šå¸¸ä¸Šéƒ¨ã«ã‚ã‚‹
            return relative_position < 0.7  # ä¸Šä½70%ä»¥å†…
        elif instruments['keyboard'] >= 0.5:
            # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã¯ä¸­ä½ã«ã‚ã‚‹
            return 0.2 < relative_position < 0.8  # ä¸­ä½60%ç¯„å›²
        
        return True
    
    def estimate_note_density(self, page: fitz.Page, staff_group: List[Tuple]) -> float:
        """V9ã®éŸ³ç¬¦å¯†åº¦æ¨å®š"""
        try:
            top_y = min(staff[1] for staff in staff_group)
            bottom_y = max(staff[1] for staff in staff_group) + 10
            rect = fitz.Rect(0, top_y, page.rect.width, bottom_y)
            
            text_blocks = page.get_text("dict", clip=rect)
            density = 0.0
            
            for block in text_blocks.get("blocks", []):
                if "bbox" in block:
                    bbox = block["bbox"]
                    density += (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
            
            total_area = rect.width * rect.height
            return density / total_area if total_area > 0 else 0.0
        except:
            return 0.0
    
    def estimate_chord_density(self, page: fitz.Page, staff_group: List[Tuple]) -> float:
        """V9ã®ã‚³ãƒ¼ãƒ‰å¯†åº¦æ¨å®š"""
        try:
            top_y = min(staff[1] for staff in staff_group) - 50
            bottom_y = min(staff[1] for staff in staff_group)
            
            text = page.get_textbox(fitz.Rect(0, top_y, page.rect.width, bottom_y))
            
            chord_patterns = [r'[A-G][#b]?m?', r'dim', r'aug', r'sus', r'maj']
            chord_count = 0
            
            for pattern in chord_patterns:
                matches = re.findall(pattern, text)
                chord_count += len(matches)
            
            return min(chord_count / 10.0, 1.0)
        except:
            return 0.0
    
    def calculate_system_rect_v9(self, staff_group: List[Tuple], page: fitz.Page) -> Optional[fitz.Rect]:
        """V9ã®ã‚·ã‚¹ãƒ†ãƒ çŸ©å½¢è¨ˆç®—"""
        if not staff_group:
            return None
        
        top_y = min(staff[1] for staff in staff_group) - 40
        bottom_y = max(staff[1] for staff in staff_group) + 30
        
        return fitz.Rect(0, top_y, page.rect.width, bottom_y)
    
    def filter_target_instruments(self, systems: List[Dict]) -> List[Dict]:
        """ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ¥½å™¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        filtered = []
        
        for system in systems:
            instruments = system['instruments_v9']
            
            # ã‚ˆã‚Šå³å¯†ãªé–¾å€¤ï¼ˆã‚­ãƒ¼ãƒœãƒ¼ãƒ‰æ¤œå‡ºã‚’æ”¹å–„ï¼‰
            vocal_ok = instruments['vocal'] >= 0.6
            keyboard_ok = instruments['keyboard'] >= 0.7  # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã¯ã‚ˆã‚Šé«˜ã„é–¾å€¤
            
            if vocal_ok or keyboard_ok:
                filtered.append(system)
        
        print(f"\\n  ğŸ¯ V14 Filtering: {len(systems)} â†’ {len(filtered)} systems")
        return filtered
    
    def create_hybrid_output(self, systems: List[Dict], original_path: str, source_pdf: fitz.Document) -> str:
        """V14ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å‡ºåŠ›ä½œæˆ"""
        if not systems:
            return None
        
        base_name = os.path.splitext(os.path.basename(original_path))[0]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = "/Users/Yodai/band_part_key_app/outputs/extracted_scores"
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, f"{base_name}_final_v14_hybrid_{timestamp}.pdf")
        
        # PDFä½œæˆ
        output_pdf = fitz.open()
        current_page = None
        current_y = 60
        
        for i, system in enumerate(systems):
            if current_page is None or current_y + 150 > 750:
                current_page = output_pdf.new_page(width=595, height=842)
                current_y = 60
            
            try:
                instruments = system['instruments_v9']
                spatial_ok = system['spatial_valid']
                
                # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
                parts = []
                if instruments['vocal'] >= 0.6: 
                    parts.append(f"Vocal({instruments['vocal']:.1f})")
                if instruments['keyboard'] >= 0.7: 
                    parts.append(f"Keyboard({instruments['keyboard']:.1f})")
                
                spatial_icon = "âœ…" if spatial_ok else "âš ï¸"
                system_info = f"V14: {', '.join(parts) if parts else 'Unknown'} {spatial_icon}"
                
                current_page.insert_text((50, current_y + 15), system_info, fontsize=10)
                
                # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼çŸ©å½¢
                rect = fitz.Rect(50, current_y + 20, 545, current_y + 120)
                color = (0.8, 0.4, 0)  # V14è­˜åˆ¥è‰²ï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ï¼‰
                current_page.draw_rect(rect, color=color, width=2)
                
                current_y += 150
                
            except Exception as e:
                print(f"    Failed to insert system {i+1}: {e}")
        
        output_pdf.save(output_path)
        output_pdf.close()
        
        print(f"\\nâœ… V14 Hybrid Extraction Complete!")
        print(f"  Output: {output_path}")
        print(f"  Systems: {len(systems)}")
        print(f"  Approach: V9 OCR + V13 Spatial validation")
        
        return output_path

if __name__ == "__main__":
    extractor = FinalSmartExtractorV14Hybrid()
    
    test_file = "/Users/Yodai/Downloads/ã ã‹ã‚‰åƒ•ã¯éŸ³æ¥½ã‚’è¾ã‚ãŸ.pdf"
    if os.path.exists(test_file):
        print("ğŸ§ª V14 HYBRID EXTRACTOR TEST")
        print("="*60)
        result = extractor.extract_smart_final(test_file)
        if result:
            print(f"\\nâœ… Test completed: {result}")
        else:
            print("\\nâŒ Test failed")
    else:
        print("âŒ Test file not found")